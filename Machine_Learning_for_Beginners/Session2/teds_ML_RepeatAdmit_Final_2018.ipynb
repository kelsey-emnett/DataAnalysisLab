{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams, gridspec\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kelsey.huntzberry/Documents/Classes/Machine_Learning_Class/Data\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/Users/kelsey.huntzberry/Documents/Classes/Machine_Learning_Class/Data\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Treatment Episode Data Set data\n",
    "teds18 = pd.read_csv('tedsa_puf_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ADMYR', 'CASEID', 'STFIPS', 'CBSA2010', 'EDUC', 'MARSTAT', 'SERVICES',\n",
       "       'DETCRIM', 'NOPRIOR', 'PSOURCE', 'ARRESTS', 'EMPLOY', 'METHUSE',\n",
       "       'PSYPROB', 'PREG', 'GENDER', 'VET', 'LIVARAG', 'DAYWAIT', 'DSMCRIT',\n",
       "       'AGE', 'RACE', 'ETHNIC', 'DETNLF', 'PRIMINC', 'SUB1', 'SUB2', 'SUB3',\n",
       "       'ROUTE1', 'ROUTE2', 'ROUTE3', 'FREQ1', 'FREQ2', 'FREQ3', 'FRSTUSE1',\n",
       "       'FRSTUSE2', 'FRSTUSE3', 'HLTHINS', 'PRIMPAY', 'FREQ_ATND_SELF_HELP',\n",
       "       'ALCFLG', 'COKEFLG', 'MARFLG', 'HERFLG', 'METHFLG', 'OPSYNFLG',\n",
       "       'PCPFLG', 'HALLFLG', 'MTHAMFLG', 'AMPHFLG', 'STIMFLG', 'BENZFLG',\n",
       "       'TRNQFLG', 'BARBFLG', 'SEDHPFLG', 'INHFLG', 'OTCFLG', 'OTHERFLG',\n",
       "       'DIVISION', 'REGION', 'IDU', 'ALCDRUG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teds18.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the data to just the 0/1 drug flag variables\n",
    "flags = teds18.filter(regex='FLG$', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the flag variables to calculate the number of drugs recorded for each individual\n",
    "NUMSUBS = flags.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate flag variables back into the 2015-17 data\n",
    "teds_wflgs = pd.concat([teds18, NUMSUBS], axis = 1)\n",
    "teds_wflgs.rename(columns={0:'NUMSUBS'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where the first substance was \"None\"\n",
    "teds_sm_temp = teds_wflgs[teds_wflgs.SUB1 != 1]\n",
    "# Remove rows where number of prior treatments is NA (target variable)\n",
    "teds_sm1 = teds_sm_temp[teds_sm_temp.NOPRIOR != -9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subset of columns\n",
    "teds_sm = teds_sm1.loc[:,['CASEID','ADMYR','AGE','GENDER','RACE','ETHNIC','EDUC','EMPLOY','VET','LIVARAG',\\\n",
    "                          'STFIPS','CBSA2010','DIVISION','REGION','SERVICES','PSOURCE','NOPRIOR','ARRESTS','ROUTE1','FRSTUSE1','FREQ1', \\\n",
    "                          'ROUTE2','FRSTUSE2', 'FREQ2','ROUTE3','FRSTUSE3','FREQ3','NUMSUBS','METHUSE','ALCFLG','PSYPROB', \\\n",
    "                          'COKEFLG','MARFLG','HERFLG','METHFLG','OPSYNFLG','PCPFLG','HALLFLG','MTHAMFLG','AMPHFLG','STIMFLG', \\\n",
    "                          'BENZFLG','TRNQFLG','BARBFLG','SEDHPFLG','INHFLG','OTCFLG','OTHERFLG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Recode age group variable\n",
    "def age_groups(series):\n",
    "    if series == 1:\n",
    "        return '12_14_years'\n",
    "    elif series == 2:\n",
    "        return '15_17_years'\n",
    "    elif series == 3:\n",
    "        return '18_20_years'\n",
    "    elif series == 4:\n",
    "        return '21_24_years'\n",
    "    elif series == 5:\n",
    "        return '25_29_years'\n",
    "    elif series == 6:\n",
    "        return '30_34_years'\n",
    "    elif series == 7:\n",
    "        return '35_39_years'\n",
    "    elif series == 8:\n",
    "        return '40_44_years'\n",
    "    elif series == 9:\n",
    "        return '45_49_years'\n",
    "    elif series == 10:\n",
    "        return '50_54_years'\n",
    "    elif series == 11:\n",
    "        return '55_64_years'\n",
    "    elif series == 12:\n",
    "        return '65_plus_years'\n",
    "    \n",
    "teds_sm1.loc[:, 'age_group'] = teds_sm1.AGE.apply(age_groups)\n",
    "\n",
    "# Change variable to an ordered factor\n",
    "teds_sm1.loc[:, 'age_group'] = pd.Categorical(teds_sm1['age_group'], categories = ['12_14_years', '15_17_years', '18_20_years',\n",
    "                                                                                   '21_24_years', '25_29_years', '30_34_years',\n",
    "                                                                                   '35_39_years', '40_44_years', '45_49_years',\n",
    "                                                                                   '50_54_years', '55_64_years', '65_plus_years'], ordered = True)\n",
    "\n",
    "# Change variable to an ordered factor with values as numbers\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'age_group'], sort = True)\n",
    "teds_sm1.loc[:, 'age_group'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode gender variable\n",
    "def gen_rc(series):\n",
    "    if series == 1:\n",
    "        return 0\n",
    "    elif series == 2:\n",
    "        return 1\n",
    "    \n",
    "teds_sm1.loc[:, 'gender'] = teds_sm1.GENDER.apply(gen_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode methadone variable\n",
    "def methadone_rc(series):\n",
    "    if series == 1:\n",
    "        return 1\n",
    "    elif series == 2:\n",
    "        return 0\n",
    "    \n",
    "teds_sm1.loc[:, 'methadone_use'] = teds_sm1.METHUSE.apply(methadone_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education recode\n",
    "def educ_rc(series):\n",
    "    if series == 1:\n",
    "        return 'No_Schooling'\n",
    "    elif series == 2:\n",
    "        return 'Grades_9_to_11'\n",
    "    elif series == 3:\n",
    "        return 'Grades_12_or_GED'\n",
    "    elif series == 4:\n",
    "        return 'College_1_to_3_years'\n",
    "    elif series == 5:\n",
    "        return 'College_4_or_more_years'\n",
    "\n",
    "teds_sm1.loc[:, 'educ'] = teds_sm1.EDUC.apply(educ_rc)\n",
    "\n",
    "# Change variable to an ordered factor\n",
    "teds_sm1.loc[:, 'educ'] = pd.Categorical(teds_sm1['educ'], categories = ['No_Schooling', 'Grades_9_to_11', 'Grades_12_or_GED',\n",
    "                                                                         'College_1_to_3_years', 'College_4_or_more_years'], ordered = True)\n",
    "\n",
    "# Change variable to an ordered factor with values as numbers\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'educ'], sort = True)\n",
    "teds_sm1.loc[:, 'educ'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record race variable\n",
    "def race_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Alaska_Native'\n",
    "    elif series == 2:\n",
    "        return 'American_Indian'\n",
    "    elif series == 3 or series == 9:\n",
    "        return 'Hawaiian_Pacific_Islander'\n",
    "    elif series == 4:\n",
    "        return 'Black'\n",
    "    elif series == 5:\n",
    "        return 'White'\n",
    "    elif series == 6:\n",
    "        return 'Asian'\n",
    "    elif series == 7:\n",
    "        return 'Other_race'\n",
    "    elif series == 8:\n",
    "        return 'Two_or_more_races'\n",
    "    \n",
    "teds_sm1.loc[:, 'race'] = teds_sm1.RACE.apply(race_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode ethnicity variable\n",
    "def ethnic_rc(series):\n",
    "    if (series >= 1 or series <= 3) or series == 5:\n",
    "        return 1\n",
    "    elif series == 4:\n",
    "        return 0\n",
    "    \n",
    "teds_sm1.loc[:, 'ethnic'] = teds_sm1.ETHNIC.apply(ethnic_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode service setting variable\n",
    "def servseta_rc(series):\n",
    "    if series == 1 or series == 2:\n",
    "        return 'Detox'\n",
    "    elif series >= 3 and series <= 5:\n",
    "        return 'Rehab_Residential'\n",
    "    elif series >= 6 and series <= 8:\n",
    "        return 'Ambulatory'\n",
    "\n",
    "teds_sm1.loc[:, 'services'] = teds_sm1.SERVICES.apply(servseta_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode marital status variable\n",
    "def marstat_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Never_Married'\n",
    "    elif series == 2:\n",
    "        return 'Married'\n",
    "    elif series == 3:\n",
    "        return 'Separated'\n",
    "    elif series == 4:\n",
    "        return 'Divorced_or_Widowed'\n",
    "\n",
    "teds_sm1.loc[:, 'marstat'] = teds_sm1.MARSTAT.apply(marstat_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode employment status variable\n",
    "def employ_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Full_time'\n",
    "    elif series == 2:\n",
    "        return 'Part_time'\n",
    "    elif series == 3:\n",
    "        return 'Unemployed'\n",
    "    elif series == 4:\n",
    "        return 'Not_in_labor_force'\n",
    "    \n",
    "teds_sm1.loc[:, 'employ'] = teds_sm1.EMPLOY.apply(employ_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode veteran variable\n",
    "def vet_rc(series):\n",
    "    if series == 1:\n",
    "        return 1\n",
    "    elif series == 2:\n",
    "        return 0\n",
    "    \n",
    "teds_sm1.loc[:, 'vet'] = teds_sm1.VET.apply(vet_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode living arrangement variable\n",
    "def livarag_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Homeless'\n",
    "    elif series == 2:\n",
    "        return 'Dependent_Living'\n",
    "    elif series == 3:\n",
    "        return 'Independent_Living'\n",
    "\n",
    "teds_sm1.loc[:, 'livarag'] = teds_sm1.LIVARAG.apply(livarag_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode arrests variable\n",
    "def arrests_rc(series):\n",
    "    if series == 0:\n",
    "        return 'None'\n",
    "    elif series == 1:\n",
    "        return 'Once'\n",
    "    elif series == 2:\n",
    "        return 'Two_or_more_times'\n",
    "    \n",
    "teds_sm1.loc[:, 'arrests'] = teds_sm1.ARRESTS.apply(arrests_rc)\n",
    "\n",
    "# Change variable to an ordered factor variable\n",
    "teds_sm1.loc[:, 'arrests'] = pd.Categorical(teds_sm1['arrests'], categories = ['None', 'Once',\n",
    "                                                                              '2 or more times'],\n",
    "                                           ordered = True)\n",
    "\n",
    "# Change variable to an ordered factor with values as numbers\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'arrests'], sort = True)\n",
    "teds_sm1.loc[:, 'arrests'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode division variable\n",
    "def division_rc(series):\n",
    "    if series == 0:\n",
    "        return 'US_Territories'\n",
    "    elif series == 1:\n",
    "        return 'New_England'\n",
    "    elif series == 2:\n",
    "        return 'Mid_Atlantic'\n",
    "    elif series == 3:\n",
    "        return 'East_North_Central'\n",
    "    elif series == 4:\n",
    "        return 'West_North_Central'\n",
    "    elif series == 5:\n",
    "        return 'South_Atlantic'\n",
    "    elif series == 6:\n",
    "        return 'East_South_Central'\n",
    "    elif series == 7:\n",
    "        return 'West_South_Central'\n",
    "    elif series == 8:\n",
    "        return 'Mountain'\n",
    "    elif series == 9:\n",
    "        return 'Pacific'\n",
    "    \n",
    "teds_sm1.loc[:, 'division'] = teds_sm1.DIVISION.apply(division_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode referral source variable\n",
    "def psource_rc(series):\n",
    "    if series == 1:\n",
    "        return 'Self_referral'\n",
    "    elif series == 2:\n",
    "        return 'Alcohol_Drug_Care_Professional'\n",
    "    elif series == 3:\n",
    "        return 'Other_Health_Care_Professional'\n",
    "    elif series == 4:\n",
    "        return 'School_Referral'\n",
    "    elif series == 5:\n",
    "        return 'Employer_Referral'\n",
    "    elif series == 6:\n",
    "        return 'Community_Referral'\n",
    "    elif series == 7:\n",
    "        return 'Court_Referral'\n",
    "    \n",
    "teds_sm1.loc[:, 'psource'] = teds_sm1.PSOURCE.apply(psource_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode number of prior treatment encounters\n",
    "def noprior_rc(series):\n",
    "    if series == 0:\n",
    "        return 0\n",
    "    elif series >= 1:\n",
    "        return 1\n",
    "    \n",
    "teds_sm1.loc[:, 'noprior'] = teds_sm1.NOPRIOR.apply(noprior_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode mental illness variable\n",
    "def psyprob_rc(series):\n",
    "    if series == 1:\n",
    "        return 1\n",
    "    elif series == 2:\n",
    "        return 0\n",
    "    \n",
    "teds_sm1.loc[:, 'psyprob'] = teds_sm1.PSYPROB.apply(psyprob_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode number of substances variable\n",
    "def numsubs_rc(series):\n",
    "    if series == 0:\n",
    "        return 'Zero_substances'\n",
    "    elif series == 1:\n",
    "        return 'One_substance'\n",
    "    elif series == 2:\n",
    "        return 'Two_substances'\n",
    "    elif series == 3:\n",
    "        return 'Three_substances'\n",
    "    \n",
    "teds_sm1.loc[:, 'numsubs'] = teds_sm1.NUMSUBS.apply(numsubs_rc)\n",
    "\n",
    "# Change first use into an ordered factor\n",
    "teds_sm1.loc[:, 'numsubs'] = pd.Categorical(teds_sm1['numsubs'], categories = ['Zero substances', 'One substance',\n",
    "                                                                               'Two substances', \"Three substances\"], ordered = True)\n",
    "\n",
    "# Convert year to factor with numeric value\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'numsubs'], sort = True)\n",
    "teds_sm1.loc[:, 'numsubs'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking age of first use from up to 3 substances in system and creating a flag if present\n",
    "def first_age_recode(column1, column2, column3):\n",
    "    if column1 == 1 or column2 == 1 or column3 == 1:\n",
    "        return '11_years_and_under'\n",
    "    elif column1 == 2 or column2 == 2 or column3 == 2:\n",
    "        return '12_14_years'\n",
    "    elif column1 == 3 or column2 == 3 or column3 == 3:\n",
    "        return '15_17_years'\n",
    "    elif column1 == 4 or column2 == 4 or column3 == 4:\n",
    "        return '18_20_years'\n",
    "    elif column1 == 5 or column2 == 5 or column3 == 5:\n",
    "        return '21_24_years'\n",
    "    elif column1 == 6 or column2 == 6 or column3 == 6:\n",
    "        return '25_29_years'\n",
    "    elif column1 == 7 or column2 == 7 or column3 == 7:\n",
    "        return '30_years_older'\n",
    "\n",
    "teds_sm1.loc[:, 'frstuse'] = teds_sm1.apply(lambda x: first_age_recode(x.FRSTUSE1, x.FRSTUSE2, x.FRSTUSE3), axis=1)\n",
    "\n",
    "# Change first use into an ordered factor\n",
    "teds_sm1.loc[:, 'frstuse'] = pd.Categorical(teds_sm1['frstuse'], categories = ['11_years_and_under', '12_14_years', '15_17_years',\n",
    "                                                                               '18_20_years', '21_24_years',\n",
    "                                                                               '25_29_years', '30_years_older'], ordered = True)\n",
    "# Convert year to factor with numeric value\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'frstuse'], sort = True)\n",
    "teds_sm1.loc[:, 'frstuse'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking frequency of use from up to 3 substances in system and creating a flag if present\n",
    "def freq_recode(column1, column2, column3):\n",
    "    if (column1 == 1 and column2 == 1 and column3 == 1):\n",
    "        return 'No_Use_Past_Month'\n",
    "    elif (column1 == 3 or column2 == 3 or column3 == 3):\n",
    "        return 'Daily_Use'\n",
    "    elif (column1 == 2 or column2 == 2 or column3 == 2):\n",
    "        return 'Some_Use'\n",
    "    elif (column1 == 1 or column2 == 1 or column3 == 1):\n",
    "        return 'No_Use_Past_Month'\n",
    "\n",
    "teds_sm1.loc[:, 'freq_use'] = teds_sm1.apply(lambda x: freq_recode(x.FREQ1, x.FREQ2, x.FREQ3), axis=1)\n",
    "\n",
    "# Change first use into an ordered factor\n",
    "teds_sm1.loc[:, 'freq_use'] = pd.Categorical(teds_sm1['freq_use'], categories = ['No_Use_Past_Month', 'Daily_Use', 'Some_Use'], ordered = True)\n",
    "# Convert year to factor with numeric value\n",
    "labels, unique = pd.factorize(teds_sm1.loc[:, 'freq_use'], sort = True)\n",
    "teds_sm1.loc[:, 'freq_use'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking administration method from up to 3 substances in system and creating a flag if present\n",
    "def oral_recode(column1, column2, column3):\n",
    "    if (column1 == 1 and column1 != None) or (column2 == 1 and column2 != None) or (column3 == 1 and column3 != None):\n",
    "        return 1\n",
    "    elif (column1 > 1 and column1 != None) or (column2 > 1 and column2 != None) or (column3 > 1 and column3 != None):\n",
    "        return 0\n",
    "\n",
    "teds_sm1.loc[:, 'oral_drug_use'] = teds_sm1.apply(lambda x: oral_recode(x.ROUTE1, x.ROUTE2, x.ROUTE3), axis=1)\n",
    "\n",
    "def smoking_recode(column1, column2, column3):\n",
    "    if (column1 == 2 and column1 != None) or (column2 == 2 and column2 != None) or (column3 == 2 and column3 != None):\n",
    "        return 1\n",
    "    elif (column1 > 0 and column1 != None) or (column2 > 0 and column2 != None) or (column3 > 0 and column3 != None):\n",
    "        return 0\n",
    "\n",
    "teds_sm1.loc[:, 'smoking_drug_use'] = teds_sm1.apply(lambda x: smoking_recode(x.ROUTE1, x.ROUTE2, x.ROUTE3), axis=1)\n",
    "\n",
    "def inhalation_recode(column1, column2, column3):\n",
    "    if (column1 == 3 and column1 != None) or (column2 == 3 and column2 != None) or (column3 == 3 and column3 != None):\n",
    "        return 1\n",
    "    elif (column1 > 0 and column1 != None) or (column2 > 0 and column2 != None) or (column3 > 0 and column3 != None):\n",
    "        return 0\n",
    "    \n",
    "teds_sm1.loc[:, 'inhale_drug_use'] = teds_sm1.apply(lambda x: inhalation_recode(x.ROUTE1, x.ROUTE2, x.ROUTE3), axis=1)\n",
    "    \n",
    "def injection_recode(column1, column2, column3):\n",
    "    if (column1 == 4 and column1 != None) or (column2 == 4 and column2 != None) or (column3 == 4 and column3 != None):\n",
    "        return 1\n",
    "    elif (column1 > 0 and column1 != None) or (column2 > 0 and column2 != None) or (column3 > 0 and column3 != None):\n",
    "        return 0\n",
    "    \n",
    "teds_sm1.loc[:, 'injection_drug_use'] = teds_sm1.apply(lambda x: injection_recode(x.ROUTE1, x.ROUTE2, x.ROUTE3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to fewer variables, mostly dropping those with many missing values\n",
    "teds_clean = teds_sm1.drop(['ADMYR', 'CASEID', 'STFIPS', 'CBSA2010', 'EDUC', 'MARSTAT', 'SERVICES',\n",
    "                            'DETCRIM', 'NOPRIOR', 'PSOURCE', 'ARRESTS', 'EMPLOY', 'METHUSE',\n",
    "                            'PSYPROB', 'PREG', 'GENDER', 'VET', 'LIVARAG', 'DAYWAIT', 'DSMCRIT',\n",
    "                            'AGE', 'RACE', 'ETHNIC', 'DETNLF', 'PRIMINC', 'SUB1', 'SUB2', 'SUB3',\n",
    "                            'ROUTE1', 'ROUTE2', 'ROUTE3', 'FREQ1', 'FREQ2', 'FREQ3', 'FRSTUSE1',\n",
    "                            'FRSTUSE2', 'FRSTUSE3', 'HLTHINS', 'PRIMPAY', 'FREQ_ATND_SELF_HELP', \n",
    "                            'IDU','REGION'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ALCFLG', 'COKEFLG', 'MARFLG', 'HERFLG', 'METHFLG', 'OPSYNFLG',\n",
       "       'PCPFLG', 'HALLFLG', 'MTHAMFLG', 'AMPHFLG', 'STIMFLG', 'BENZFLG',\n",
       "       'TRNQFLG', 'BARBFLG', 'SEDHPFLG', 'INHFLG', 'OTCFLG', 'OTHERFLG',\n",
       "       'DIVISION', 'ALCDRUG', 'NUMSUBS', 'age_group', 'gender',\n",
       "       'methadone_use', 'educ', 'race', 'ethnic', 'services', 'marstat',\n",
       "       'employ', 'vet', 'livarag', 'arrests', 'division', 'psource', 'noprior',\n",
       "       'psyprob', 'numsubs', 'frstuse', 'freq_use', 'oral_drug_use',\n",
       "       'smoking_drug_use', 'inhale_drug_use', 'injection_drug_use'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teds_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unemployed            577217\n",
       "Not_in_labor_force    545991\n",
       "Full_time             280470\n",
       "Part_time             111805\n",
       "Name: employ, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teds_clean.employ.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data for easy analysis\n",
    "teds_clean = teds_clean.sample(n = 200000, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ALCFLG', 'COKEFLG', 'MARFLG', 'HERFLG', 'METHFLG', 'OPSYNFLG',\n",
       "       'PCPFLG', 'HALLFLG', 'MTHAMFLG', 'AMPHFLG', 'STIMFLG', 'BENZFLG',\n",
       "       'TRNQFLG', 'BARBFLG', 'SEDHPFLG', 'INHFLG', 'OTCFLG', 'OTHERFLG',\n",
       "       'DIVISION', 'ALCDRUG', 'NUMSUBS', 'age_group', 'gender',\n",
       "       'methadone_use', 'educ', 'race', 'ethnic', 'services', 'marstat',\n",
       "       'employ', 'vet', 'livarag', 'arrests', 'division', 'psource', 'noprior',\n",
       "       'psyprob', 'numsubs', 'frstuse', 'freq_use', 'oral_drug_use',\n",
       "       'smoking_drug_use', 'inhale_drug_use', 'injection_drug_use'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teds_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#teds_clean.to_csv(\"teds_data_small.csv\",index=False)\n",
    "teds_clean = pd.read_csv(\"teds_data_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for unordered categorical variables\n",
    "# Need to make sure at least one category from each variable is removed during feature selection\n",
    "teds2018 = pd.get_dummies(teds_clean, columns=['race','psource','division','ethnic','services','marstat','employ',\n",
    "                                               'livarag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ALCFLG', 'COKEFLG', 'MARFLG', 'HERFLG', 'METHFLG', 'OPSYNFLG',\n",
       "       'PCPFLG', 'HALLFLG', 'MTHAMFLG', 'AMPHFLG', 'STIMFLG', 'BENZFLG',\n",
       "       'TRNQFLG', 'BARBFLG', 'SEDHPFLG', 'INHFLG', 'OTCFLG', 'OTHERFLG',\n",
       "       'DIVISION', 'ALCDRUG', 'NUMSUBS', 'age_group', 'gender',\n",
       "       'methadone_use', 'educ', 'vet', 'arrests', 'noprior', 'psyprob',\n",
       "       'numsubs', 'frstuse', 'freq_use', 'oral_drug_use', 'smoking_drug_use',\n",
       "       'inhale_drug_use', 'injection_drug_use', 'race_Alaska_Native',\n",
       "       'race_American_Indian', 'race_Asian', 'race_Black',\n",
       "       'race_Hawaiian_Pacific_Islander', 'race_Other_race',\n",
       "       'race_Two_or_more_races', 'race_White',\n",
       "       'psource_Alcohol_Drug_Care_Professional', 'psource_Community_Referral',\n",
       "       'psource_Court_Referral', 'psource_Employer_Referral',\n",
       "       'psource_Other_Health_Care_Professional', 'psource_School_Referral',\n",
       "       'psource_Self_referral', 'division_East_North_Central',\n",
       "       'division_East_South_Central', 'division_Mid_Atlantic',\n",
       "       'division_Mountain', 'division_New_England', 'division_Pacific',\n",
       "       'division_South_Atlantic', 'division_US_Territories',\n",
       "       'division_West_North_Central', 'division_West_South_Central',\n",
       "       'ethnic_1', 'services_Ambulatory', 'services_Detox',\n",
       "       'services_Rehab_Residential', 'marstat_Divorced_or_Widowed',\n",
       "       'marstat_Married', 'marstat_Never_Married', 'marstat_Separated',\n",
       "       'employ_Full_time', 'employ_Not_in_labor_force', 'employ_Part_time',\n",
       "       'employ_Unemployed', 'livarag_Dependent_Living', 'livarag_Homeless',\n",
       "       'livarag_Independent_Living'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teds2018.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALCFLG</th>\n",
       "      <th>COKEFLG</th>\n",
       "      <th>MARFLG</th>\n",
       "      <th>HERFLG</th>\n",
       "      <th>METHFLG</th>\n",
       "      <th>OPSYNFLG</th>\n",
       "      <th>PCPFLG</th>\n",
       "      <th>HALLFLG</th>\n",
       "      <th>MTHAMFLG</th>\n",
       "      <th>AMPHFLG</th>\n",
       "      <th>...</th>\n",
       "      <th>marstat_Married</th>\n",
       "      <th>marstat_Never_Married</th>\n",
       "      <th>marstat_Separated</th>\n",
       "      <th>employ_Full_time</th>\n",
       "      <th>employ_Not_in_labor_force</th>\n",
       "      <th>employ_Part_time</th>\n",
       "      <th>employ_Unemployed</th>\n",
       "      <th>livarag_Dependent_Living</th>\n",
       "      <th>livarag_Homeless</th>\n",
       "      <th>livarag_Independent_Living</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1345611</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332688</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>376764</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1483754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1838556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1609196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1168347</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ALCFLG  COKEFLG  MARFLG  HERFLG  METHFLG  OPSYNFLG  PCPFLG  HALLFLG  \\\n",
       "1345611       1        0       0       0        0         0       0        0   \n",
       "332688        1        0       0       0        0         0       0        0   \n",
       "376764        1        0       0       1        0         0       0        0   \n",
       "41708         0        0       0       0        0         0       0        0   \n",
       "1483754       0        0       1       0        0         0       0        0   \n",
       "...         ...      ...     ...     ...      ...       ...     ...      ...   \n",
       "1838556       0        1       1       1        0         0       0        0   \n",
       "1609196       0        0       0       1        0         0       0        0   \n",
       "1168347       1        0       1       0        0         0       0        0   \n",
       "226932        0        0       0       0        0         0       0        0   \n",
       "670375        0        1       0       1        0         0       0        0   \n",
       "\n",
       "         MTHAMFLG  AMPHFLG  ...  marstat_Married  marstat_Never_Married  \\\n",
       "1345611         0        0  ...                1                      0   \n",
       "332688          0        0  ...                0                      0   \n",
       "376764          0        0  ...                0                      0   \n",
       "41708           0        0  ...                1                      0   \n",
       "1483754         0        0  ...                0                      1   \n",
       "...           ...      ...  ...              ...                    ...   \n",
       "1838556         0        0  ...                0                      0   \n",
       "1609196         0        0  ...                0                      1   \n",
       "1168347         0        0  ...                0                      0   \n",
       "226932          1        0  ...                0                      0   \n",
       "670375          1        0  ...                0                      0   \n",
       "\n",
       "         marstat_Separated  employ_Full_time  employ_Not_in_labor_force  \\\n",
       "1345611                  0                 1                          0   \n",
       "332688                   0                 0                          0   \n",
       "376764                   0                 0                          0   \n",
       "41708                    0                 0                          0   \n",
       "1483754                  0                 1                          0   \n",
       "...                    ...               ...                        ...   \n",
       "1838556                  0                 0                          0   \n",
       "1609196                  0                 0                          1   \n",
       "1168347                  1                 1                          0   \n",
       "226932                   0                 0                          1   \n",
       "670375                   0                 0                          0   \n",
       "\n",
       "         employ_Part_time  employ_Unemployed  livarag_Dependent_Living  \\\n",
       "1345611                 0                  0                         0   \n",
       "332688                  0                  1                         1   \n",
       "376764                  0                  1                         0   \n",
       "41708                   0                  0                         0   \n",
       "1483754                 0                  0                         0   \n",
       "...                   ...                ...                       ...   \n",
       "1838556                 0                  1                         0   \n",
       "1609196                 0                  0                         0   \n",
       "1168347                 0                  0                         0   \n",
       "226932                  0                  0                         1   \n",
       "670375                  0                  1                         0   \n",
       "\n",
       "         livarag_Homeless  livarag_Independent_Living  \n",
       "1345611                 0                           1  \n",
       "332688                  0                           0  \n",
       "376764                  1                           0  \n",
       "41708                   0                           0  \n",
       "1483754                 0                           1  \n",
       "...                   ...                         ...  \n",
       "1838556                 0                           1  \n",
       "1609196                 0                           1  \n",
       "1168347                 0                           1  \n",
       "226932                  0                           0  \n",
       "670375                  1                           0  \n",
       "\n",
       "[200000 rows x 76 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teds2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop response variable and year since only 2017 will be used in final modeling\n",
    "data = teds2018.drop(columns = ['noprior'])\n",
    "# Recording column names to object for later use in feature selection\n",
    "columns = data.columns\n",
    "# Create data frame with just the response variable\n",
    "response = teds2018.loc[:,['noprior']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change response and predictor data frames to numpy arrays\n",
    "data_imp_np = np.array(data)\n",
    "response_np = np.array(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create holdout data set and keep remaining 80% in one data frame\n",
    "# Used stratefied random sampling because there was class imbalance\n",
    "sss = StratifiedShuffleSplit(n_splits = 2, test_size=0.2, random_state=0)\n",
    "\n",
    "sss.get_n_splits(data_imp_np, response_np)\n",
    "\n",
    "for train_index, test_index in sss.split(data_imp_np, response_np):\n",
    "    x_train_temp, x_test = data_imp_np[train_index], data_imp_np[test_index]\n",
    "    y_train_temp, y_test = response_np[train_index], response_np[test_index]\n",
    "\n",
    "# Split the remaining data into a training and validation data set (50% and 30% respectively)\n",
    "sss_valid = StratifiedShuffleSplit(n_splits = 2, test_size = 0.3, random_state = 10)  \n",
    "    \n",
    "for train_index, test_index in sss_valid.split(x_train_temp, y_train_temp):\n",
    "    x_train, x_validation = x_train_temp[train_index], x_train_temp[test_index]\n",
    "    y_train, y_validation = y_train_temp[train_index], y_train_temp[test_index]\n",
    "\n",
    "    \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_validation = np.array(x_validation)\n",
    "y_validation = np.array(y_validation)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing data with mode\n",
    "# Will put this in a pipeline when we choose our final model\n",
    "simple_imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "my_imputer = simple_imputer.fit(x_train)\n",
    "x_train = my_imputer.transform(x_train)\n",
    "x_validation = my_imputer.transform(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7034106893362863"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of how you use k-fold cross validation (by default for classification models it used stratified k-fold cross validation)\n",
    "log_reg_kfold_cv = LogisticRegression()\n",
    "accuracy_scores = cross_val_score(log_reg_kfold_cv, x_train, y_train, cv=5, scoring='accuracy')\n",
    "accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-defined function to create formatted confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"\\nNormalized confusion matrix\")\n",
    "    else:\n",
    "        print('\\nConfusion matrix, without normalization')\n",
    "\n",
    "    print ()\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize = 15)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=20, fontsize = 14)\n",
    "    plt.yticks(tick_marks, classes, fontsize = 14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize = 14)\n",
    "    plt.xlabel('Predicted label', fontsize = 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run logistic regression model as a baseline\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_logreg = logreg_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59     19409\n",
      "           1       0.72      0.82      0.77     28591\n",
      "\n",
      "    accuracy                           0.70     48000\n",
      "   macro avg       0.69      0.67      0.68     48000\n",
      "weighted avg       0.70      0.70      0.69     48000\n",
      "\n",
      "\n",
      "Normalized confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_validation, valid_predict_logreg))\n",
    "\n",
    "# Assign classes\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_logreg = confusion_matrix(y_validation, valid_predict_logreg)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_logreg, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Logistic Regression')\n",
    "\n",
    "# Results: Accuracy is 68%, but very bad accuracy for identifying first admission patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression grid search across multiple penalties\n",
    "penalties = [0.2, 0.5, 0.7, 0.9]\n",
    "\n",
    "results_lasso = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    c_value = penalties[i]\n",
    "\n",
    "    lasso_model = LogisticRegression(penalty = 'l1', C = c_value)\n",
    "\n",
    "    lasso_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_lasso = lasso_model.predict(x_validation)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_lasso, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_lasso, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'c'] = c_value\n",
    "    class_report.loc[:, 'model'] = 'Lasso Regression'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_lasso = pd.concat([results_lasso, class_report], axis = 0)\n",
    "\n",
    "# Results: Results were little better than logistic regression and varied little when penalty was changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>c</th>\n",
       "      <th>model</th>\n",
       "      <th>model_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.666645</td>\n",
       "      <td>0.526405</td>\n",
       "      <td>0.588283</td>\n",
       "      <td>19409.0</td>\n",
       "      <td>0.702063</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>First Treatment Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718675</td>\n",
       "      <td>0.821307</td>\n",
       "      <td>0.766571</td>\n",
       "      <td>28591.0</td>\n",
       "      <td>0.702063</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>2+ Treatment Episodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.666515</td>\n",
       "      <td>0.527024</td>\n",
       "      <td>0.588618</td>\n",
       "      <td>19409.0</td>\n",
       "      <td>0.702125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>First Treatment Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718862</td>\n",
       "      <td>0.820993</td>\n",
       "      <td>0.766540</td>\n",
       "      <td>28591.0</td>\n",
       "      <td>0.702125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>2+ Treatment Episodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.666428</td>\n",
       "      <td>0.527024</td>\n",
       "      <td>0.588584</td>\n",
       "      <td>19409.0</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>First Treatment Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718845</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.766500</td>\n",
       "      <td>28591.0</td>\n",
       "      <td>0.702083</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>2+ Treatment Episodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.666450</td>\n",
       "      <td>0.527281</td>\n",
       "      <td>0.588753</td>\n",
       "      <td>19409.0</td>\n",
       "      <td>0.702146</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>First Treatment Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718938</td>\n",
       "      <td>0.820853</td>\n",
       "      <td>0.766522</td>\n",
       "      <td>28591.0</td>\n",
       "      <td>0.702146</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>2+ Treatment Episodes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score  support  accuracy    c             model  \\\n",
       "0   0.666645  0.526405  0.588283  19409.0  0.702063  0.2  Lasso Regression   \n",
       "1   0.718675  0.821307  0.766571  28591.0  0.702063  0.2  Lasso Regression   \n",
       "0   0.666515  0.527024  0.588618  19409.0  0.702125  0.5  Lasso Regression   \n",
       "1   0.718862  0.820993  0.766540  28591.0  0.702125  0.5  Lasso Regression   \n",
       "0   0.666428  0.527024  0.588584  19409.0  0.702083  0.7  Lasso Regression   \n",
       "1   0.718845  0.820923  0.766500  28591.0  0.702083  0.7  Lasso Regression   \n",
       "0   0.666450  0.527281  0.588753  19409.0  0.702146  0.9  Lasso Regression   \n",
       "1   0.718938  0.820853  0.766522  28591.0  0.702146  0.9  Lasso Regression   \n",
       "\n",
       "               model_value  \n",
       "0  First Treatment Episode  \n",
       "1    2+ Treatment Episodes  \n",
       "0  First Treatment Episode  \n",
       "1    2+ Treatment Episodes  \n",
       "0  First Treatment Episode  \n",
       "1    2+ Treatment Episodes  \n",
       "0  First Treatment Episode  \n",
       "1    2+ Treatment Episodes  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Ridge regression grid search across multiple penalties\n",
    "penalties = [0.2, 0.5, 0.7, 0.9]\n",
    "\n",
    "results_ridge = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    c_value = penalties[i]\n",
    "\n",
    "    ridge_model = LogisticRegression(penalty = 'l2', C = c_value)\n",
    "\n",
    "    ridge_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_ridge = ridge_model.predict(x_validation)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_ridge, output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_ridge, output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'c'] = c_value\n",
    "    class_report.loc[:, 'model'] = 'Ridge Regression'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_ridge = pd.concat([results_ridge, class_report], axis = 0)\n",
    "    \n",
    "# Results: Results were little better than logistic regression and varied little when penalty was changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>c</th>\n",
       "      <th>model</th>\n",
       "      <th>model_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.671368</td>\n",
       "      <td>0.520213</td>\n",
       "      <td>0.586203</td>\n",
       "      <td>162966.0</td>\n",
       "      <td>0.704886</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>First Treatment Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.720041</td>\n",
       "      <td>0.828942</td>\n",
       "      <td>0.770663</td>\n",
       "      <td>242596.0</td>\n",
       "      <td>0.704886</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>2+ Treatment Episodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.671340</td>\n",
       "      <td>0.520133</td>\n",
       "      <td>0.586142</td>\n",
       "      <td>162966.0</td>\n",
       "      <td>0.704856</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>First Treatment Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.720008</td>\n",
       "      <td>0.828946</td>\n",
       "      <td>0.770646</td>\n",
       "      <td>242596.0</td>\n",
       "      <td>0.704856</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>2+ Treatment Episodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.671342</td>\n",
       "      <td>0.520127</td>\n",
       "      <td>0.586139</td>\n",
       "      <td>162966.0</td>\n",
       "      <td>0.704856</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>First Treatment Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.720007</td>\n",
       "      <td>0.828950</td>\n",
       "      <td>0.770647</td>\n",
       "      <td>242596.0</td>\n",
       "      <td>0.704856</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>2+ Treatment Episodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.671334</td>\n",
       "      <td>0.520108</td>\n",
       "      <td>0.586124</td>\n",
       "      <td>162966.0</td>\n",
       "      <td>0.704849</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>First Treatment Episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.719999</td>\n",
       "      <td>0.828950</td>\n",
       "      <td>0.770643</td>\n",
       "      <td>242596.0</td>\n",
       "      <td>0.704849</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>2+ Treatment Episodes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score   support  accuracy    c             model  \\\n",
       "0   0.671368  0.520213  0.586203  162966.0  0.704886  0.2  Ridge Regression   \n",
       "1   0.720041  0.828942  0.770663  242596.0  0.704886  0.2  Ridge Regression   \n",
       "0   0.671340  0.520133  0.586142  162966.0  0.704856  0.5  Ridge Regression   \n",
       "1   0.720008  0.828946  0.770646  242596.0  0.704856  0.5  Ridge Regression   \n",
       "0   0.671342  0.520127  0.586139  162966.0  0.704856  0.7  Ridge Regression   \n",
       "1   0.720007  0.828950  0.770647  242596.0  0.704856  0.7  Ridge Regression   \n",
       "0   0.671334  0.520108  0.586124  162966.0  0.704849  0.9  Ridge Regression   \n",
       "1   0.719999  0.828950  0.770643  242596.0  0.704849  0.9  Ridge Regression   \n",
       "\n",
       "               model_value  \n",
       "0  First Treatment Episode  \n",
       "1    2+ Treatment Episodes  \n",
       "0  First Treatment Episode  \n",
       "1    2+ Treatment Episodes  \n",
       "0  First Treatment Episode  \n",
       "1    2+ Treatment Episodes  \n",
       "0  First Treatment Episode  \n",
       "1    2+ Treatment Episodes  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_model = LogisticRegression(penalty = 'l1', C = 0.2)\n",
    "lasso_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_lasso = lasso_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.678579</td>\n",
       "      <td>race_Alaska_Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.665620</td>\n",
       "      <td>PCPFLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.515259</td>\n",
       "      <td>psource_Alcohol_Drug_Care_Professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.460193</td>\n",
       "      <td>HERFLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.436749</td>\n",
       "      <td>METHFLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>-0.692815</td>\n",
       "      <td>division_US_Territories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>-0.703937</td>\n",
       "      <td>division_West_South_Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>-0.705250</td>\n",
       "      <td>division_South_Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>-0.741591</td>\n",
       "      <td>division_East_South_Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>-1.822635</td>\n",
       "      <td>division_Pacific</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficients                                features\n",
       "35      1.678579                      race_Alaska_Native\n",
       "6       0.665620                                  PCPFLG\n",
       "43      0.515259  psource_Alcohol_Drug_Care_Professional\n",
       "3       0.460193                                  HERFLG\n",
       "4       0.436749                                 METHFLG\n",
       "..           ...                                     ...\n",
       "57     -0.692815                 division_US_Territories\n",
       "59     -0.703937             division_West_South_Central\n",
       "56     -0.705250                 division_South_Atlantic\n",
       "51     -0.741591             division_East_South_Central\n",
       "55     -1.822635                        division_Pacific\n",
       "\n",
       "[75 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coefs = pd.DataFrame(columns, list(lasso_model.coef_)).reset_index()\n",
    "lasso_coefs.columns = ['coefficients','features']\n",
    "lasso_coefs = lasso_coefs.sort_values(by='coefficients', ascending=False)\n",
    "lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ridge_model = LogisticRegression(penalty = 'l2', C = 0.2)\n",
    "ridge_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_ridge = ridge_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.667012</td>\n",
       "      <td>race_Alaska_Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.996623</td>\n",
       "      <td>division_Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.703668</td>\n",
       "      <td>division_West_North_Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.547479</td>\n",
       "      <td>PCPFLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.513665</td>\n",
       "      <td>psource_Alcohol_Drug_Care_Professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>-0.551260</td>\n",
       "      <td>psource_Employer_Referral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>-0.568989</td>\n",
       "      <td>employ_Full_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>-0.570661</td>\n",
       "      <td>STIMFLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>-0.795161</td>\n",
       "      <td>division_US_Territories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>-0.979992</td>\n",
       "      <td>division_Pacific</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficients                                features\n",
       "35      1.667012                      race_Alaska_Native\n",
       "53      0.996623                       division_Mountain\n",
       "58      0.703668             division_West_North_Central\n",
       "6       0.547479                                  PCPFLG\n",
       "43      0.513665  psource_Alcohol_Drug_Care_Professional\n",
       "..           ...                                     ...\n",
       "46     -0.551260               psource_Employer_Referral\n",
       "68     -0.568989                        employ_Full_time\n",
       "10     -0.570661                                 STIMFLG\n",
       "57     -0.795161                 division_US_Territories\n",
       "55     -0.979992                        division_Pacific\n",
       "\n",
       "[75 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_coefs = pd.DataFrame(columns, list(ridge_model.coef_)).reset_index()\n",
    "ridge_coefs.columns = ['coefficients','features']\n",
    "ridge_coefs = ridge_coefs.sort_values(by='coefficients', ascending=False)\n",
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-cb8c893f6686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run default gradient boosted trees model to get baseline accuracy and feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgbt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgbt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvalid_predict_gbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1545\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1608\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1609\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1244\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run default gradient boosted trees model to get baseline accuracy and feature importances\n",
    "gbt_model = GradientBoostingClassifier(random_state=75)\n",
    "gbt_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_gbt = gbt_model.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation metrics and feature importances to narrow down variables I need\n",
    "print(classification_report(y_validation, valid_predict_gbt))\n",
    "\n",
    "# Print feature importances to subset data set to more important variables\n",
    "print(pd.DataFrame({'features': data_imputed.columns,\n",
    "                    'importances': gbt_model.feature_importances_}).sort_values(['importances'], ascending = 0))\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_gbt = confusion_matrix(y_validation, valid_predict_gbt)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_gbt, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=75)\n",
    "rf_model.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_rf = rf_model_default.predict(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics and feature importances to narrow down variables I need\n",
    "print(classification_report(y_validation, valid_predict_rf))\n",
    "\n",
    "# Print feature importances to subset data set to more important variables\n",
    "print(pd.DataFrame({'features': data_imputed.columns,\n",
    "                    'importances': rf_model.feature_importances_}).sort_values(['importances'], ascending = 0))\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_rf = confusion_matrix(y_validation, valid_predict_rf)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_rf, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a medium-sized data set with all variables above 0.005 in importance\n",
    "x_train_sm = x_train[:, [7, 0, 3, 45, 2, 49, 43, 26, 48, 8, 56, 41, 39, 40, 25, 37, 1, 44, 11, 4, 42, 58, 33, 30, 57, 27, 47, 28]]\n",
    "x_validation_sm = x_validation[:, [7, 0, 3, 45, 2, 49, 43, 26, 48, 8, 56, 41, 39, 40, 25, 37, 1, 44, 11, 4, 42, 58, 33, 30, 57, 27, 47, 28]]\n",
    "x_test_sm = x_test[:, [7, 0, 3, 45, 2, 49, 43, 26, 48, 8, 56, 41, 39, 40, 25, 37, 1, 44, 11, 4, 42, 58, 33, 30, 57, 27, 47, 28]]\n",
    "features_sm = data_imputed.iloc[:, [7, 0, 3, 45, 2, 49, 43, 26, 48, 8, 56, 41, 39, 40, 25, 37, 1, 44, 11, 4, 42, 58, 33, 30, 57, 27, 47, 28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression with a smaller number of variables, grid search for penalties most accurate for larger data set\n",
    "penalties = [0.5, 0.9]\n",
    "\n",
    "results_ridge_sm = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,2):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    c_value = penalties[i]\n",
    "\n",
    "    ridge_model = LogisticRegression(penalty = 'l2', C = c_value)\n",
    "\n",
    "    ridge_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_ridge = ridge_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_ridge, output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_ridge, output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'c'] = c_value\n",
    "    class_report.loc[:, 'model'] = 'Ridge Regression'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_ridge_sm = pd.concat([results_ridge_sm, class_report], axis = 0)\n",
    "    \n",
    "# Results: Accuracy dropped to 67% with smaller number of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ridge_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy of default model with medium and large data frames\n",
    "# Run default gradient boosted trees model to get baseline accuracy and feature importances\n",
    "gbt_model_sm = GradientBoostingClassifier(random_state=75)\n",
    "gbt_model_sm.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_gbt_sm = gbt_model_sm.predict(x_validation_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics are the same as with the full data set so stick with the limited data set\n",
    "print(classification_report(y_validation, valid_predict_gbt_sm))\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_gbt_sm = confusion_matrix(y_validation, valid_predict_gbt_sm)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_gbt_sm, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Gradient Boosted Trees')\n",
    "\n",
    "# Results: Accuracy increased to 70%, but first treatment episode accuracy did not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosted trees, grid search varying the number of estimators\n",
    "n_estimators = [150, 200, 300]\n",
    "\n",
    "results_gbt_nEst = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    est_value = n_estimators[i]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, n_estimators = est_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'n_estimators'] = est_value\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_nEst = pd.concat([results_gbt_nEst, class_report], axis = 0)\n",
    "    \n",
    "# Results: Accuracy increased with the number of estimators, but 200 and 300 were not different enough to justify the extra processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_nEst\n",
    "# Minimal increase in accuracy for 300 and 200 instead of 150 so will stick with 150 for further testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient boosted trees, varying the maximum depth of the tree\n",
    "max_depth = [5, 7, 9, 15]\n",
    "\n",
    "results_gbt_max_depth = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    max_depth_value = max_depth[i]\n",
    "    \n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, n_estimators = 200, max_depth = max_depth_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'max_depth'] = max_depth_value\n",
    "    class_report.loc[:, 'n_estimators'] = 200\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_max_depth = pd.concat([results_gbt_max_depth, class_report], axis = 0)\n",
    "    \n",
    "# Results: Accuracy increased with the depth of the tree, but did not increase enough from 7 to 9 to justify extra processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient boosted trees, grid search varying the learning rate\n",
    "# Going to compare the results of this to the results from n_estimators because these hyperparameters present a trade off\n",
    "learning_rate = [0.05, 0.15, 0.3, 0.35]\n",
    "\n",
    "results_gbt_learn_rate = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    learn_rate_value = learning_rate[i]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, learning_rate = learn_rate_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'learning_rate'] = learn_rate_value\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_learn_rate = pd.concat([results_gbt_learn_rate, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy optimal with a learning rate of 0.3, results more accurate than with n_estimators altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient boosted trees, grid search varying learning rate and maximum depth of trees\n",
    "learning_rate = [0.05, 0.15, 0.3]\n",
    "max_depth = [5, 7, 9]\n",
    "\n",
    "results_gbt_lrate_depth = pd.DataFrame([])\n",
    "\n",
    "for i, j in itertools.product(range(0,3), range(0,3)):\n",
    "    \n",
    "    print(i)\n",
    "    print(j)\n",
    "    \n",
    "    max_depth_value = max_depth[i]\n",
    "    \n",
    "    learning_rate_value = learning_rate[j]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, max_depth = max_depth_value,\n",
    "                                           learning_rate = learning_rate_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'max_depth'] = max_depth_value\n",
    "    class_report.loc[:, 'learning_rate'] = learning_rate_value\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_lrate_depth = pd.concat([results_gbt_lrate_depth, class_report], axis = 0)\n",
    "\n",
    "# Results: Optimal results with max_depth = 7 and learning_rate = 0.3\n",
    "# Accuracy = 0.72, F1-score for 1st treatment: 0.54, F1-score for 2+ treatments: 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_gbt_lrate_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gradient boosted trees, attempting early stopping with minimum impurity decrease\n",
    "min_imp_dec = [0.25, 0.5, 0.1]\n",
    "\n",
    "results_gbt_imp_dec = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    min_imp_value = min_imp_dec[i]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, learning_rate = 0.3, \n",
    "                                           min_impurity_decrease = min_imp_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'min_impurity_decrease'] = min_imp_value\n",
    "    class_report.loc[:, 'learning_rate'] = 0.3\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_imp_dec = pd.concat([results_gbt_imp_dec, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy decreased by several points on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_imp_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosted trees, grid search varying maximum depth and max_features\n",
    "max_depth = [0.5, 0.1]\n",
    "max_features = [7, 10, 15]\n",
    "\n",
    "results_gbt_feat_maxdepth = pd.DataFrame([])\n",
    "\n",
    "for i, j in itertools.product(range(0,2), range(0,3)):\n",
    "    \n",
    "    max_depth_value = max_depth[i]\n",
    "    \n",
    "    max_feat_value = max_features[j]\n",
    "\n",
    "    gbt_model = GradientBoostingClassifier(random_state = 75, max_depth = max_depth_value,\n",
    "                                           learning_rate = 0.3, max_features = max_feat_value)\n",
    "\n",
    "    gbt_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_gbt = gbt_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'max_depth'] = min_imp_dec_value\n",
    "    class_report.loc[:, 'max_features'] = max_feat_value\n",
    "    class_report.loc[:, 'learning_rate'] = 0.3\n",
    "    class_report.loc[:, 'model'] = 'Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_gbt_feat_maxdepth = pd.concat([results_gbt_feat_maxdepth, class_report], axis = 0)\n",
    "\n",
    "# Results: Adding a maximum feature parameter changed the model metrics very little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gbt_feat_maxdepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Boosted Trees, grid search with varying sub-samples\n",
    "sub_sample = [0.8, 0.9, 0.95]\n",
    "\n",
    "results_stoch_grad = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    subsample_value = sub_sample[i]\n",
    "\n",
    "    stoch_grad_model = GradientBoostingClassifier(random_state = 75, learning_rate = 0.3, max_depth = 9,\n",
    "                                          subsample = subsample_value)\n",
    "\n",
    "    stoch_grad_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_stoch_grad = stoch_grad_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_stoch_grad, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_gbt, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'subsample'] = subsample_value\n",
    "    class_report.loc[:, 'learning_rate'] = 0.3\n",
    "    class_report.loc[:, 'max_depth'] = 9\n",
    "    class_report.loc[:, 'model'] = 'Stochastic Gradient Boosted Trees'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_stoch_grad = pd.concat([results_stoch_grad, class_report], axis = 0)\n",
    "\n",
    "# Results: Adding a sub-sampling parameter changed the model metrics very little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stoch_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a default random forest model\n",
    "rf_model_default = RandomForestClassifier(random_state=75)\n",
    "rf_model_default.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_rf_def = rf_model_default.predict(x_validation_sm)\n",
    "\n",
    "# Results: Accuracy is 69% with F1-score of 52% for first treatment and 77% for 2+ treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_validation, valid_predict_rf_def))\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_rf_def = confusion_matrix(y_validation, valid_predict_rf_def)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_rf_def, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, grid search varying the number of estimators\n",
    "n_estimators = [200, 300, 350]\n",
    "\n",
    "results_rf_n_est = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    n_est_value = n_estimators[i]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = n_est_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'n_estimators'] = n_est_value\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_n_est = pd.concat([results_rf_n_est, class_report], axis = 0)\n",
    "\n",
    "# Results: An increase in accuracy until 300, enough to warrant keeping 300 over 200 although similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_n_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, grid search varying the minimum samples per split\n",
    "min_samples_split = [5, 9, 12]\n",
    "\n",
    "results_rf_min_samp = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    min_samp_split_value = min_samples_split[i]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                     min_samples_split = min_samp_split_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'min_samples_split'] = min_samp_split_value\n",
    "    class_report.loc[:, 'n_estimators'] = 300\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_min_samp = pd.concat([results_rf_min_samp, class_report], axis = 0)\n",
    "    \n",
    "# Results: Accuracy optimized at min_samples_split = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_min_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest, testing early stopping with a grid search on minimum impurity decrease per split\n",
    "min_impurity_decrease = [0.03, 0.05, 0.1]\n",
    "\n",
    "results_rf_imp_dec = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    min_imp_dec_value = min_impurity_decrease[i]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                     min_impurity_decrease = min_imp_dec_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'min_impurity_decrease'] = min_imp_dec_value\n",
    "    class_report.loc[:, 'n_estimators'] = 300\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_imp_dec = pd.concat([results_rf_imp_dec, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy dropped a large amount to mid-60%s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_imp_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest, grid search varying the maximum features and minimum samples per split\n",
    "max_features = [7, 10, 15]\n",
    "min_samples_split = [9, 12]\n",
    "\n",
    "results_rf_feat_samp_split = pd.DataFrame([])\n",
    "\n",
    "for i, j in itertools.product(range(0,3), range(0,2)):\n",
    "    \n",
    "    print(i)\n",
    "    print(j)\n",
    "    \n",
    "    max_feat_value = max_features[i]\n",
    "    min_samp_split_value = min_samples_split[j]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                     max_features = max_feat_value, min_samples_split = min_samp_split_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'n_estimators'] = 300\n",
    "    class_report.loc[:, 'max_features'] = max_feat_value\n",
    "    class_report.loc[:, 'min_samples_split'] = min_samp_split_value\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_feat_samp_split = pd.concat([results_rf_feat_samp_split, class_report], axis = 0)\n",
    "\n",
    "# Results: The above changes attempted did not increase accuracy above the other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_feat_samp_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest, varying the penalty/weight put on wrong answers for 0, which is more commonly misclassified\n",
    "# Also varying minimum samples per split\n",
    "min_samples_split = [9, 12]\n",
    "weight = [1.5, 2, 2.5, 3]\n",
    "\n",
    "results_rf_feat_samp_split = pd.DataFrame([])\n",
    "\n",
    "for i, j in itertools.product(range(0,2), range(0,4)):\n",
    "    \n",
    "    print(i)\n",
    "    print(j)\n",
    "    \n",
    "    max_feat_value = n_estimators[i]\n",
    "    weight_value = weight[j]\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                     class_weight = {0:weight_value}, min_samples_split = min_samp_split_value)\n",
    "\n",
    "    rf_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_rf = rf_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_rf, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'n_estimators'] = 300\n",
    "    class_report.loc[:, 'weight_zero'] = weight_value\n",
    "    class_report.loc[:, 'min_samples_split'] = min_samp_split_value\n",
    "    class_report.loc[:, 'model'] = 'Random Forest'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    results_rf_feat_samp_split = pd.concat([results_rf_feat_samp_split, class_report], axis = 0)\n",
    "\n",
    "# Results: Classification of 0 values greatly improved without sacrificing much overall accuracy\n",
    "# Accuracy = 0.70, F1-score for 0 = 0.62, F1-score for 1 = 0.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf_feat_samp_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors, grid search varying k with Euclidean distance\n",
    "k = [5, 8, 12, 15]\n",
    "\n",
    "knn_euclidean = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    k_value = k[i]\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = k_value, p = 2, n_jobs = 7)\n",
    "\n",
    "    knn_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_knn = knn_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_knn, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_knn, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'k'] = k_value\n",
    "    class_report.loc[:, 'distance_metric'] = 'Euclidean'\n",
    "    class_report.loc[:, 'model'] = 'K-Nearest Neighbors'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    knn_euclidean = pd.concat([knn_euclidean, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy dropped from mid to high 60s with lower F1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors, grid search varying k for Minkowski distance\n",
    "k = [5, 8, 12, 15]\n",
    "\n",
    "knn_minkowski = pd.DataFrame([])\n",
    "\n",
    "for i in range(0,4):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    k_value = k[i]\n",
    "\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = k_value, n_jobs = 7)\n",
    "\n",
    "    knn_model.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "\n",
    "    valid_predict_knn = knn_model.predict(x_validation_sm)\n",
    "\n",
    "    class_report = pd.DataFrame(classification_report(y_validation, valid_predict_knn, \n",
    "                                                      output_dict = True)).iloc[:, 0:2]\n",
    "\n",
    "    class_report = class_report.T\n",
    "\n",
    "    class_report.loc[:, 'accuracy'] = pd.DataFrame(classification_report(y_validation, valid_predict_knn, \n",
    "                                                                         output_dict = True)).iloc[1, 2]\n",
    "    class_report.loc[:, 'k'] = k_value\n",
    "    class_report.loc[:, 'distance_metric'] = 'Minkowski'\n",
    "    class_report.loc[:, 'model'] = 'K-Nearest Neighbors'\n",
    "    class_report.loc[:, 'model_value'] = ['First Treatment Episode', '2+ Treatment Episodes']\n",
    "\n",
    "    knn_minkowski = pd.concat([knn_minkowski, class_report], axis = 0)\n",
    "\n",
    "# Results: Accuracy looked virtually identical to Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model for each model type\n",
    "## Lasso Regression\n",
    "lasso_model_final = LogisticRegression(penalty = 'l1', C = 0.5)\n",
    "lasso_model_final.fit(x_train, np.ravel(y_train, order='C'))\n",
    "valid_predict_lasso_final = lasso_model_final.predict(x_validation)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_lasso = confusion_matrix(y_validation, valid_predict_lasso_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_lasso, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Lasso Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge Regression\n",
    "ridge_model_final = LogisticRegression(penalty = 'l2', C = 0.5)\n",
    "ridge_model_final.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_ridge_final = ridge_model_final.predict(x_validation_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_ridge = confusion_matrix(y_validation, valid_predict_ridge_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_ridge, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Ridge Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Boosted Trees\n",
    "gbt_model_final = GradientBoostingClassifier(random_state = 75, learning_rate = 0.3, max_depth = 7)\n",
    "gbt_model_final.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_gbt_final = gbt_model_final.predict(x_validation_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_gbt = confusion_matrix(y_validation, valid_predict_gbt_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_gbt, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "rf_model_final = RandomForestClassifier(random_state = 75, n_jobs = 7, n_estimators = 300,\n",
    "                                        class_weight = {0:2}, min_samples_split = 12)\n",
    "rf_model_final.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_rf_final = rf_model_final.predict(x_validation_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_rf = confusion_matrix(y_validation, valid_predict_rf_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_rf, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-Nearest Neighbors\n",
    "knn_model_final = KNeighborsClassifier(n_neighbors = 12, n_jobs = 7)\n",
    "knn_model_final.fit(x_train_sm, np.ravel(y_train, order='C'))\n",
    "valid_predict_knn_final = knn_model_final.predict(x_validation_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_knn = confusion_matrix(y_validation, valid_predict_knn_final)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_knn, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix, Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Building and printing ROC curves for all final models\n",
    "classes = ['First', 'Two or More']\n",
    "\n",
    "probs1 = lasso_model_final.predict_proba(x_validation)\n",
    "probs1 = probs1[:, 1]\n",
    "\n",
    "probs2 = rf_model_final.predict_proba(x_validation_sm)\n",
    "probs2 = probs2[:, 1]\n",
    "\n",
    "probs3 = gbt_model_final.predict_proba(x_validation_sm)\n",
    "probs3 = probs3[:, 1]\n",
    "\n",
    "probs4 = logreg_model.predict_proba(x_validation)\n",
    "probs4 = probs4[:, 1]\n",
    "\n",
    "probs5 = knn_model_final.predict_proba(x_validation_sm)\n",
    "probs5 = probs5[:, 1]\n",
    "\n",
    "probs6 = ridge_model_final.predict_proba(x_validation_sm)\n",
    "probs6 = probs6[:, 1]\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs3)\n",
    "auc = metrics.roc_auc_score(y_validation, probs3)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Gradient Boosted Trees, auc=\"+str(round(auc, 2)), color = 'red')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs2)\n",
    "auc = metrics.roc_auc_score(y_validation, probs2)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Random Forest, auc=\"+str(round(auc, 2)), color = 'blue')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs5)\n",
    "auc = metrics.roc_auc_score(y_validation, probs5)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"K-Nearest Neighbors, auc=\"+str(round(auc, 2)), color = 'darkorchid')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs4)\n",
    "auc = metrics.roc_auc_score(y_validation, probs4)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, auc=\"+str(round(auc, 2)), color = 'gold')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs1)\n",
    "auc = metrics.roc_auc_score(y_validation, probs1)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Lasso Regression, auc=\"+str(round(auc, 2)), color = 'darkorange')\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(y_validation, probs6)\n",
    "auc = metrics.roc_auc_score(y_validation, probs6)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.plot(fpr,tpr,label=\"Ridge Regression, auc=\"+str(round(auc, 2)), color = 'green')\n",
    "\n",
    "plt.legend(loc=0, fontsize = 'x-large')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize = 35)\n",
    "plt.xticks(fontsize = 25)\n",
    "plt.yticks(fontsize = 25)\n",
    "plt.xlabel('False Positive Rate', fontsize = 30)\n",
    "plt.ylabel('True Positive Rate', fontsize = 30)\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 15\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('NumPriorTreat_ROC_Curve_Comp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Chosen: Random Forest with min_samples_split = 12, n_estimators = 300, and a weight of 2 on misclassifications of zero\n",
    "# Above model shows lower accuracy on the ROC curve than gradient boosted trees but is the only model that classified 0s significantly higher than chance\n",
    "# Testing model with final holdout data set\n",
    "valid_predict_rf_ho = rf_model_final.predict(x_test_sm)\n",
    "\n",
    "class_names = ['First', 'Two or More']\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix_rf_ho = confusion_matrix(y_test, valid_predict_rf_ho)\n",
    "np.set_printoptions(precision=2) # set NumPy to 2 decimal places\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cnf_matrix_rf, classes=class_names, normalize=True,\n",
    "                      title='Normalized Confusion Matrix, Random Forest, Holdout Data')\n",
    "\n",
    "pd.DataFrame(classification_report(y_test, valid_predict_rf_ho, \n",
    "                                   output_dict = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
